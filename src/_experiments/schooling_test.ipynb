{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import manifold\n",
    "from cs_systems.lstm_vae import VariationalRecurrentAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ctable(characters):\n",
    "    def encode(sequence):\n",
    "        encoded_s = []\n",
    "        for sc in sequence:\n",
    "            enc = [1 if sc == c else 0 for i, c in enumerate(characters)]\n",
    "            encoded_s.append(enc)\n",
    "\n",
    "        return encoded_s\n",
    "\n",
    "    def decode(sequence, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            sequence = sequence.argmax(axis=-1)\n",
    "\n",
    "        return [characters[i] for i in sequence]\n",
    "\n",
    "    return encode, decode\n",
    "\n",
    "\n",
    "def vectorize(data, encode):\n",
    "    return np.array([encode(sequence) for sequence in data], dtype='float32')\n",
    "\n",
    "\n",
    "def generate_tonal_data(size, timesteps):\n",
    "    samples = []\n",
    "    samples_reverse = []\n",
    "\n",
    "    diatonic = np.array([0, 2, 4, 5, 7, 9, 11])\n",
    "    characters = np.array([str(i) for i in range(24,46)])\n",
    "    \n",
    "    seen = []\n",
    "    while len(samples) < size:\n",
    "        root = random.randint(0, len(characters) - 1)\n",
    "        diatonic_indices = (diatonic + root) % 11\n",
    "        diatonic_characters = characters[diatonic_indices]\n",
    "\n",
    "        notes = [random.randint(0, len(diatonic_characters) - 1) for _ in range(timesteps)]\n",
    "        tune = [diatonic_characters[i] for i in notes]\n",
    "        tune_as_string = \"\".join(tune)\n",
    "\n",
    "        if tune_as_string in seen:\n",
    "            continue\n",
    "        else:\n",
    "            seen.append(tune_as_string)\n",
    "\n",
    "        samples.append(tune)\n",
    "        samples_reverse.append(tune[::-1])\n",
    "\n",
    "    return samples, samples_reverse\n",
    "\n",
    "def generate_atonal_data(size, timesteps):\n",
    "    samples = []\n",
    "    samples_reverse = []\n",
    "    # -- one octave + equal amount of rests. 50/50 chance of rest?\n",
    "    characters = [str(i) for i in range(24, 36)] \n",
    "    seen = []\n",
    "    while len(samples) < size:\n",
    "        notes = [random.randint(0, len(characters) - 1) for _ in range(timesteps)]\n",
    "        tune = [characters[i] for i in notes]\n",
    "        tune_as_string = \"\".join(tune)\n",
    "\n",
    "        if tune_as_string in seen:\n",
    "            continue\n",
    "        else:\n",
    "            seen.append(tune_as_string)\n",
    "\n",
    "        samples.append(tune)\n",
    "        samples_reverse.append(tune[::-1])\n",
    "\n",
    "    return samples, samples_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10000, 10, 13) (10000, 10, 13) (10000,)\n"
    }
   ],
   "source": [
    "characters = [' '] + [str(i) for i in range(24, 36)]\n",
    "encode, decode = create_ctable(characters)\n",
    "\n",
    "timesteps = 10\n",
    "hidden_dim = 128\n",
    "latent_dim = 32\n",
    "\n",
    "atonal_x, atonal_x_reverse = generate_atonal_data(10000, timesteps)\n",
    "# tonal_x, tonal_x_reverse = generate_tonal_data(10000, timesteps)\n",
    "\n",
    "x_reverse = vectorize(atonal_x_reverse, encode)\n",
    "x = vectorize(atonal_x, encode)\n",
    "\n",
    "y = np.zeros(10000)\n",
    "print(x_reverse.shape, x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalRecurrentAutoEncoder(timesteps, len(characters), hidden_dim, latent_dim, RNN=tf.keras.layers.LSTM)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "vae.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 10000 samples\nEpoch 1/50\n10000/10000 [==============================] - 5s 471us/sample - loss: 2.5146\nEpoch 2/50\n10000/10000 [==============================] - 2s 235us/sample - loss: 2.3741\nEpoch 3/50\n10000/10000 [==============================] - 2s 231us/sample - loss: 2.3047\nEpoch 4/50\n10000/10000 [==============================] - 3s 257us/sample - loss: 2.2519\nEpoch 5/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 2.2143\nEpoch 6/50\n10000/10000 [==============================] - 2s 249us/sample - loss: 2.1831\nEpoch 7/50\n10000/10000 [==============================] - 3s 265us/sample - loss: 2.1549\nEpoch 8/50\n10000/10000 [==============================] - 3s 253us/sample - loss: 2.1221\nEpoch 9/50\n10000/10000 [==============================] - 3s 258us/sample - loss: 2.0878\nEpoch 10/50\n10000/10000 [==============================] - 3s 267us/sample - loss: 2.0560\nEpoch 11/50\n10000/10000 [==============================] - 3s 251us/sample - loss: 2.0223\nEpoch 12/50\n10000/10000 [==============================] - 3s 252us/sample - loss: 1.9887\nEpoch 13/50\n10000/10000 [==============================] - 3s 258us/sample - loss: 1.9560\nEpoch 14/50\n10000/10000 [==============================] - 3s 253us/sample - loss: 1.9240\nEpoch 15/50\n10000/10000 [==============================] - 3s 252us/sample - loss: 1.8943\nEpoch 16/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.8680\nEpoch 17/50\n10000/10000 [==============================] - 2s 250us/sample - loss: 1.8470\nEpoch 18/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.8281\nEpoch 19/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.8017\nEpoch 20/50\n10000/10000 [==============================] - 3s 255us/sample - loss: 1.7797\nEpoch 21/50\n10000/10000 [==============================] - 3s 255us/sample - loss: 1.7620\nEpoch 22/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.7358\nEpoch 23/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.7148\nEpoch 24/50\n10000/10000 [==============================] - 2s 248us/sample - loss: 1.6928\nEpoch 25/50\n10000/10000 [==============================] - 3s 262us/sample - loss: 1.6709\nEpoch 26/50\n10000/10000 [==============================] - 3s 252us/sample - loss: 1.6502\nEpoch 27/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.6341\nEpoch 28/50\n10000/10000 [==============================] - 3s 257us/sample - loss: 1.6139\nEpoch 29/50\n10000/10000 [==============================] - 3s 260us/sample - loss: 1.6013\nEpoch 30/50\n10000/10000 [==============================] - 3s 259us/sample - loss: 1.5832\nEpoch 31/50\n10000/10000 [==============================] - 3s 259us/sample - loss: 1.5653\nEpoch 32/50\n10000/10000 [==============================] - 3s 259us/sample - loss: 1.5476\nEpoch 33/50\n10000/10000 [==============================] - 3s 257us/sample - loss: 1.5325\nEpoch 34/50\n10000/10000 [==============================] - 3s 260us/sample - loss: 1.5168\nEpoch 35/50\n10000/10000 [==============================] - 3s 264us/sample - loss: 1.5033\nEpoch 36/50\n10000/10000 [==============================] - 3s 270us/sample - loss: 1.4841\nEpoch 37/50\n10000/10000 [==============================] - 3s 300us/sample - loss: 1.4716\nEpoch 38/50\n10000/10000 [==============================] - 3s 266us/sample - loss: 1.4545\nEpoch 39/50\n10000/10000 [==============================] - 3s 254us/sample - loss: 1.4349\nEpoch 40/50\n10000/10000 [==============================] - 3s 263us/sample - loss: 1.4223\nEpoch 41/50\n10000/10000 [==============================] - 3s 266us/sample - loss: 1.4033\nEpoch 42/50\n10000/10000 [==============================] - 3s 281us/sample - loss: 1.3886\nEpoch 43/50\n10000/10000 [==============================] - 3s 275us/sample - loss: 1.3750\nEpoch 44/50\n10000/10000 [==============================] - 3s 336us/sample - loss: 1.3612\nEpoch 45/50\n10000/10000 [==============================] - 3s 285us/sample - loss: 1.3498\nEpoch 46/50\n10000/10000 [==============================] - 3s 286us/sample - loss: 1.3371\nEpoch 47/50\n10000/10000 [==============================] - 3s 289us/sample - loss: 1.3156\nEpoch 48/50\n10000/10000 [==============================] - 3s 298us/sample - loss: 1.3055\nEpoch 49/50\n10000/10000 [==============================] - 3s 280us/sample - loss: 1.2938\nEpoch 50/50\n10000/10000 [==============================] - 3s 278us/sample - loss: 1.2784\n"
    }
   ],
   "source": [
    "history = vae.fit(x_reverse, x, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Artefacts\n",
    "\n",
    "Below 10 new artefacts are introduced and learned by the agent. It stops when it succesfully recreates the original input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Epoch 000\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2711\nmisclassifieds: 8\nTraining Epoch 001\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.1625\nmisclassifieds: 10\nTraining Epoch 002\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.1314\nmisclassifieds: 10\nTraining Epoch 003\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.1772\nmisclassifieds: 9\nTraining Epoch 004\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2977\nmisclassifieds: 9\nTraining Epoch 005\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2739\nmisclassifieds: 8\nTraining Epoch 006\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.4053\nmisclassifieds: 8\nTraining Epoch 007\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2051\nmisclassifieds: 9\nTraining Epoch 008\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2200\nmisclassifieds: 9\nTraining Epoch 009\nTrain on 10 samples\n10/10 [==============================] - 0s 2ms/sample - loss: 1.3355\nmisclassifieds: 10\nTraining Epoch 010\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.1217\nmisclassifieds: 9\nTraining Epoch 011\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.2928\nmisclassifieds: 8\nTraining Epoch 012\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9666\nmisclassifieds: 10\nTraining Epoch 013\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.1946\nmisclassifieds: 9\nTraining Epoch 014\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.0490\nmisclassifieds: 7\nTraining Epoch 015\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9881\nmisclassifieds: 8\nTraining Epoch 016\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.8800\nmisclassifieds: 9\nTraining Epoch 017\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9313\nmisclassifieds: 8\nTraining Epoch 018\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 1.0127\nmisclassifieds: 3\nTraining Epoch 019\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.8761\nmisclassifieds: 6\nTraining Epoch 020\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9050\nmisclassifieds: 5\nTraining Epoch 021\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.8691\nmisclassifieds: 5\nTraining Epoch 022\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9143\nmisclassifieds: 6\nTraining Epoch 023\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.9308\nmisclassifieds: 6\nTraining Epoch 024\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.8554\nmisclassifieds: 7\nTraining Epoch 025\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7829\nmisclassifieds: 3\nTraining Epoch 026\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7506\nmisclassifieds: 7\nTraining Epoch 027\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7605\nmisclassifieds: 5\nTraining Epoch 028\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7544\nmisclassifieds: 5\nTraining Epoch 029\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.8343\nmisclassifieds: 4\nTraining Epoch 030\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6879\nmisclassifieds: 2\nTraining Epoch 031\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7027\nmisclassifieds: 3\nTraining Epoch 032\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6845\nmisclassifieds: 4\nTraining Epoch 033\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7032\nmisclassifieds: 5\nTraining Epoch 034\nTrain on 10 samples\n10/10 [==============================] - 0s 2ms/sample - loss: 0.7015\nmisclassifieds: 2\nTraining Epoch 035\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6640\nmisclassifieds: 6\nTraining Epoch 036\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6354\nmisclassifieds: 5\nTraining Epoch 037\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6675\nmisclassifieds: 3\nTraining Epoch 038\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.7283\nmisclassifieds: 6\nTraining Epoch 039\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6149\nmisclassifieds: 3\nTraining Epoch 040\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.5807\nmisclassifieds: 2\nTraining Epoch 041\nTrain on 10 samples\n10/10 [==============================] - 0s 2ms/sample - loss: 0.5741\nmisclassifieds: 4\nTraining Epoch 042\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6433\nmisclassifieds: 2\nTraining Epoch 043\nTrain on 10 samples\n10/10 [==============================] - 0s 3ms/sample - loss: 0.5478\nmisclassifieds: 2\nTraining Epoch 044\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6529\nmisclassifieds: 7\nTraining Epoch 045\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6562\nmisclassifieds: 4\nTraining Epoch 046\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.5389\nmisclassifieds: 4\nTraining Epoch 047\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.5314\nmisclassifieds: 3\nTraining Epoch 048\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.5812\nmisclassifieds: 4\nTraining Epoch 049\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6839\nmisclassifieds: 4\nTraining Epoch 050\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.5695\nmisclassifieds: 4\nTraining Epoch 051\nTrain on 10 samples\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6342\nmisclassifieds: 0\nAll X reconstructed correctly.\n"
    }
   ],
   "source": [
    "new_x, new_x_reverse = generate_atonal_data(10, timesteps)\n",
    "\n",
    "new_x_reverse = vectorize(new_x_reverse, encode)\n",
    "new_x = vectorize(new_x, encode)\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f\"Training Epoch {epoch:03d}\")\n",
    "    history = vae.fit(new_x_reverse, new_x, epochs=1, batch_size=128)\n",
    "\n",
    "    reconstructions = vae.predict(new_x_reverse)\n",
    "\n",
    "    misclassifieds = 0\n",
    "    for original, reconstruction in zip(new_x, reconstructions):\n",
    "        a = decode(original)\n",
    "        b = decode(reconstruction)\n",
    "\n",
    "        if not np.array_equiv(a, b):\n",
    "            misclassifieds += 1\n",
    "\n",
    "    print('misclassifieds:', misclassifieds)\n",
    "    if misclassifieds == 0:\n",
    "        print(\"All X reconstructed correctly.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Artefacts\n[['28' '32' '30' '24' '29' '27' '33' '28' '35' '27']\n ['29' '24' '27' '35' '27' '25' '31' '27' '35' '33']\n ['24' '25' '35' '32' '32' '29' '35' '32' '35' '26']\n ['24' '33' '34' '27' '31' '31' '30' '29' '35' '31']\n ['28' '31' '30' '34' '28' '31' '28' '32' '26' '28']\n ['29' '27' '25' '26' '33' '27' '28' '32' '31' '33']\n ['30' '34' '24' '28' '24' '31' '26' '34' '31' '27']\n ['24' '24' '26' '30' '34' '31' '34' '33' '32' '30']\n ['25' '35' '24' '28' '28' '24' '28' '35' '31' '26']\n ['27' '30' '25' '29' '28' '29' '35' '32' '34' '35']]\n\nMean Artefact\n[['24' '24' '27' '27' '31' '31' '32' '32' '26' '26']]\n"
    }
   ],
   "source": [
    "z_mean, z_logvar, z = vae.encode(new_x_reverse)\n",
    "\n",
    "new_artefact = z.numpy().mean(axis=0).reshape(1, 32)\n",
    "new_artefact = np.array(vae.decode(new_artefact))\n",
    "\n",
    "print('Artefacts')\n",
    "print(np.array([decode(x) for x in new_x]))\n",
    "\n",
    "print('\\nMean Artefact')\n",
    "print(np.array([decode(new_artefact[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenvaa460c9e5f7342379adccfb6a8521cac",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}